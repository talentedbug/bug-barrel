---
date: '2024-12-22T22:19:21+08:00'
draft: false
title: 'AI èžåˆå¼€å‘çš„çˆ¬è™«å®žè·µ'
typora-copy-images-to: '../../static/img/${filename}.d'
---

~~æœ¬è›¾å­å¯æ˜¯**è›¾å­**ï¼Œæœ€æ“…é•¿çš„å°±æ˜¯çˆ¬è™«å•¦~~ ðŸ˜„

å…¶å®žä¸»è¦æ˜¯æœ¬è›¾å­æœ€è¿‘çœ‹åˆ° GitHub Copilot ç«Ÿç„¶æœ‰äº†å…è´¹è®¡åˆ’ï¼ˆä¸çŸ¥é“æ˜¯ä¸æ˜¯è¢« CoCopilot é€¼çš„ï¼‰ï¼Œåˆæƒ³èµ·æ¥ä»Šå¹´éƒ½ 2024 å¹´äº†ï¼Œä¸ä¼šèžåˆ AI å¼€å‘çš„ç¨‹åºå‘˜å¿«è¢«æ—¶ä»£æ·˜æ±°äº†ã€‚äºŽæ˜¯æœ¬è›¾å­å°±è¯•ç€æ‹¿ Microsoft Copilotï¼Œåœ¨å°½å¯èƒ½å°‘çš„äººå·¥å¹²é¢„ä¸‹ï¼Œå†™å‡ºçš„ä»£ç å¯ç”¨æ€§ç©¶ç«Ÿå¦‚ä½•ã€‚

ä¸ºä»€ä¹ˆç”¨ Microsoft Copilotï¼Ÿè¿™æ˜¯æœ¬è›¾å­å·²çŸ¥çš„ GPT-4o æ¨¡åž‹é™åˆ¶æœ€å°‘çš„ï¼Œä¸Šä¸‹æ–‡ã€å¯¹è¯æ•°é‡ã€æ–‡ç”Ÿå›¾éƒ½æ²¡æœ‰ç¡¬é™åˆ¶ã€‚

> æœ¬æ–‡ä¸­ç”Ÿæˆçš„æ‰€æœ‰ä»£ç éƒ½å­˜äºŽ [talentedbug/bugscrawler](https://github.com/talentedbug/bugscrawler) ä¸­ï¼Œä½¿ç”¨æ³¨æ„ç‰ˆæƒé£Žé™©ã€‚

## ðŸ¹ å¿«æ‰‹

ç½‘ä¸Šæœ‰å¾ˆå¤šå¿«æ‰‹å°å§å§çŸ­è§†é¢‘çš„ APIï¼Œéƒ½æ˜¯å¼€æ”¾çš„ï¼Œä¸»è¦æ˜¯ç”±äºŽå¿«æ‰‹å› ä¸ºä¸æ˜ŽåŽŸå› ï¼Œå¹¶æœªå¯¹å…¶è§†é¢‘è®¾ç½®åç›—é“¾ï¼Œåªè¦èƒ½èŽ·å¾—é“¾æŽ¥åˆ—è¡¨å°±èƒ½ä¸‹è½½ï¼Œè€Œè¿™å¹¶ä¸æ˜¯å¾ˆéš¾ã€‚

è¿™ä¸ªæŒ‘æˆ˜åº”è¯¥æ˜¯æœ€å°çš„ï¼Œå› ä¸ºå¯ä»¥ç›´æŽ¥èŽ·å¾—é“¾æŽ¥ï¼Œä¸‹è½½å³å¯ã€‚

```python
import requests
import os

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'
}

def download_file(url, directory, file_number):
    try:
        if not os.path.exists(directory):
            os.makedirs(directory)
        
        file_name = os.path.join(directory, f"{file_number}.mp4")
        with requests.get(url, stream=True, headers=headers) as r:
            r.raise_for_status()
            with open(file_name, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
        print(f"[Info] Downloaded: {file_name}")
    except requests.RequestException as e:
        print(f"[Warning] Download error: {e}")

def main(api_url, loop_times):
    for i in range(loop_times):
        try:
            download_file(api_url, 'img', i+1)
        except Exception as e:
            print(f"[Warning] Error occurred: {e}")

if __name__ == "__main__":
    api_url = "https://api.dwo.cc/api/ksvideo"
    loop_times = 1000  # Define the number of times to loop
    main(api_url, loop_times)

```

ä¸ºäº†å¤„ç† API éšæœºç»™å‡ºé“¾æŽ¥é‡å¤çš„é—®é¢˜ï¼Œåˆè®© Copilot å†™äº†ä¸ªåŽ»é‡è„šæœ¬ï¼Œå¯ä»¥å¤šçº¿ç¨‹æ‰§è¡Œã€‚

```python
import os
import hashlib
import concurrent.futures

def hash_file(file_path):
    """Generates a hash for a file."""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as file:
        buf = file.read()
        hasher.update(buf)
    return hasher.hexdigest(), file_path

def find_duplicates(directory):
    """Finds duplicate files in the given directory."""
    hashes = {}
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Generate list of files
        file_paths = [
            os.path.join(root, file_name) 
            for root, _, files in os.walk(directory) 
            for file_name in files
        ]
        
        # Process files in parallel
        future_to_file = {executor.submit(hash_file, file_path): file_path for file_path in file_paths}
        
        for future in concurrent.futures.as_completed(future_to_file):
            try:
                file_hash, file_path = future.result()
                if file_hash in hashes:
                    hashes[file_hash].append(file_path)
                else:
                    hashes[file_hash] = [file_path]
            except Exception as e:
                print(f"[Warning] Error processing file: {e}")

    return hashes

def main():
    directory = '/var/www/img/kuaishou/img'  # Replace with the path to your directory
    duplicates = find_duplicates(directory)
    
    if duplicates:
        print("[Info] Duplicate files found and cleaned:")
        for file_hash, file_list in duplicates.items():
            if len(file_list) > 1:
                print(f"[Info] {' | '.join(file_list)}")
                for file_to_remove in file_list[1:]:
                    os.remove(file_to_remove)
                    print(f"[Info] Removed: {file_to_remove}")
    else:
        print("[Info] No duplicate files found.")

if __name__ == "__main__":
    main()

```

è¿™ä¸¤ä¸ªè„šæœ¬æ€»å…±ç”¨äº† 6 ä¸ª Promptï¼Œè€—æ—¶ 15 åˆ†é’Ÿè¾¾åˆ°æ­£å¸¸è¿è¡ŒçŠ¶æ€ï¼Œæ•ˆæžœè¿˜æ˜¯ç›¸å½“ä¸é”™çš„ã€‚Copilot ç»™å‡ºçš„ç¨‹åºåŸºæœ¬éƒ½å¯ä»¥ç›´æŽ¥è¿è¡Œï¼Œå°‘æ•°ä¸Žå®žé™…æƒ…å†µéžå¸¸ç›¸å…³çš„åœ°æ–¹éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ã€‚

> å…·ä½“ä½¿ç”¨çš„ Prompt éƒ½åœ¨ä¸Šè¿°ä»“åº“çš„ä»£ç æ³¨é‡Šä¸­ï¼Œä¸ºäº†ç®€æ˜Žè¿™é‡Œå°±ä¸ç²˜è´´äº†ã€‚

## ðŸŒŸ ç§€äººç½‘

è¿™é‡Œçš„æƒ…å†µå°±æ¯”è¾ƒå¤æ‚äº†ã€‚è™½ç„¶ç§€äººç½‘æ²¡æœ‰è®¾ç½®åç›—é“¾ï¼Œä½†æ˜¯æ²¡æœ‰ APIï¼Œéœ€è¦è‡ªå·±è®¾ç½®æ­£åˆ™è¡¨è¾¾å¼æ¥åŒ¹é…é“¾æŽ¥ã€‚

ä½†æ˜¯ Microsoft Copilot ç«Ÿç„¶ä¸æ”¯æŒç›´æŽ¥è®¿é—®ç½‘é¡µï¼Œå¤åˆ¶ç²˜è´´ HTML åˆè¶…å‡ºå­—ç¬¦é™åˆ¶â€¦â€¦åªå¥½æœ¬è›¾å­è‡ªå·±æ¥å†™äº†ï¼Œé‚£è¿™ä¸ªæµ‹è¯•å°±æ²¡ä»€ä¹ˆæ„æ€ï¼Œæœ€éš¾çš„éƒ¨åˆ†éƒ½è·³è¿‡äº†â€¦â€¦

å—ï¼Ÿ

æœ¬è›¾å­è‡ªå·±å†™äº†ä¸€ç‰ˆä»£ç ï¼Œå‘çŽ°æ ¹æœ¬æ²¡æ³•é•¿æœŸæ‰§è¡Œï¼Œä¸€ä¸ªå°å°çš„é”™è¯¯å°±ä¼šè®©ä»–ç›´æŽ¥ä¸¢ Exceptionã€‚äºŽæ˜¯æœ¬è›¾å­å°†éœ€æ±‚è¾“å…¥äº† Copilotï¼Œå¹¶ä¸”å‘Šè¯‰å®ƒäº†æ­£åˆ™è¡¨è¾¾å¼ï¼Œå®ƒç»™å‡ºçš„ç¬¬ä¸€ç‰ˆä»£ç å¯è¯»æ€§å°±ç›¸å½“é«˜ï¼Œå¹¶ä¸”åŸºæœ¬å¯ä»¥è¿è¡Œã€‚åŽé¢æœ¬è›¾å­åªå°†è°ƒè¯•é”™è¯¯å‘Šè¯‰å®ƒï¼Œç»è¿‡ 6 ä¸ª Prompt çš„ä¿®æ­£ï¼Œå®ƒç»™å‡ºäº†æ­£ç¡®ä»£ç ã€‚

æœ¬è›¾å­å·²ç»æ‰§è¡Œè¿™æ®µè„šæœ¬ 3 å¤©äº†ï¼Œå®ƒä¾ç„¶æ²¡æœ‰å‡ºçŽ°é—®é¢˜ã€‚~~æ„Ÿè§‰å®ƒå¾ˆå¿«å°±è¦æ›¿ä»£æœ¬è›¾å­å‚åŠ ç§‹æ‹›äº†â€¦â€¦~~

æœ€åŽç»™å‡ºçš„ä»£ç ï¼Œæœ¬è›¾å­ç¨å¾®æ‰‹åŠ¨ä¿®æ”¹äº†ä¸€ç‚¹ï¼š

```python
import os
import re
import requests
from urllib.parse import urljoin
import warnings

def get_max_dir_num():
    img_dir = 'img'
    if not os.path.exists(img_dir):
        os.makedirs(img_dir)
    
    max_num = 13121
    for dir_name in os.listdir(img_dir):
        try:
            num = int(dir_name)
            if num > max_num:
                max_num = num
        except ValueError:
            pass
    return max_num

def download_images(begin_num):
    url = f'https://www.xiurenwang.cc/{begin_num}.html'
    print(f"[Info] Page URL: {url}")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        print(f'[Error] Failed to download page {begin_num}: Code {response.status_code}')
        return

    html = response.text
    pattern = r'(?<=href=")//ooo111\.ka123\.sbs/pic/.*?/.*?/.*?\.jpg'
    matches = re.findall(pattern, html)

    if not matches:
        print(f'[Error] Failed to download page {begin_num}: No images found')
        return

    initial_img_url = urljoin('https:', matches[0])
    initial_img_num = int(initial_img_url.split('/')[-1].split('.')[0])

    img_path = f'img/{begin_num}/{initial_img_num}.jpg'
    os.makedirs(os.path.dirname(img_path), exist_ok=True)

    headers = {
        'Referer': url,
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    # Download images with increasing numbers
    for i in range(initial_img_num, initial_img_num + 1200):  # adjust the range as needed
        img_url = initial_img_url.replace(f'{initial_img_num}.jpg', f'{i}.jpg')
        response = requests.get(img_url, headers=headers, verify=False)
        if response.status_code != 200:
            print(f"[Error] Failed to download image {img_url}: Code {response.status_code}")
            print("[Info] Increament terminated")
            break
        img_path = f'img/{begin_num}/{i}.jpg'
        with open(img_path, 'wb') as f:
            f.write(response.content)
        print(f"[Info] Downloaded image {img_url} to {img_path}")
        os.system(f"jpegoptim {img_path} -m40 -q")
        if os.popen(f"identify -format '%w' {img_path}").read() > 1000 or os.popen(f"identify -format '%h' {img_path}").read() > 1000:
            os.system(f"convert -resize 50% {img_path} {img_path}")
        print(f"[Info] Compressed image {img_path}")

    # Download images with decreasing numbers
    for i in range(initial_img_num - 1, 0, -1):  # adjust the range as needed
        img_url = initial_img_url.replace(f'{initial_img_num}.jpg', f'{i}.jpg')
        response = requests.get(img_url, headers=headers, verify=False)
        if response.status_code != 200:
            print(f"[Error] Failed to download image {img_url}: Code {response.status_code}")
            print("[Info] Decreament terminated")
            break
        img_path = f'img/{begin_num}/{i}.jpg'
        with open(img_path, 'wb') as f:
            f.write(response.content)
        print(f"[Info] Downloaded image {img_url} to {img_path}")

def main():
    import sys
    if len(sys.argv) > 1:
        begin_num = int(sys.argv[1])
    else:
        max_dir_num = get_max_dir_num()
        if max_dir_num > 13121:
            begin_num = max_dir_num
        else:
            begin_num = max_dir_num
    if begin_num == 13121:
        print(f"[Info] Use default begin_num {begin_num}")
    elif len(sys.argv) > 1:
        print(f"[Info] Use argument begin_num {begin_num}")
    else:
        print(f"[Info] Use resuming begin_num {begin_num}")

    current_max = 16466
    warnings.filterwarnings("ignore")
    while begin_num <= current_max:
        print(f"[Info] Proceeding page {begin_num}")
        download_images(begin_num)
        begin_num += 1

if __name__ == '__main__':
    main()

```

å¦å¤–æœ¬è›¾å­è¿˜è®© Copilot æŒ‰è¦æ±‚å†™äº†ä¸€ä¸ªå±•ç¤ºå›¾ç‰‡çš„å‰ç«¯ï¼Œåˆæ”¹äº†ä¸€ä¸ªç”¨äºŽä¸Šæ–‡è§†é¢‘çš„ï¼ŒHTML æ¯”è¾ƒé•¿ï¼Œå¤§å®¶å°±åˆ°ä»“åº“é‡Œçœ‹å§ã€‚

## ðŸ›¡ å›°éš¾ï¼šæ¬¡å…ƒå²›

æ¬¡å…ƒå²›çš„å›¾ç‰‡é“¾æŽ¥å°±ä¸æ˜¯é‚£ä¹ˆè§„æ•´äº†ï¼Œè€Œä¸”è¿˜æœ‰æ··æ·†é¡¹å’Œé˜²ç›—é“¾ï¼Œæœ¬è›¾å­åœ¨ä¸Šé¢ç§€äººç½‘çš„å¯¹è¯åŽ†å²ä¸Šç»™å‡º HTMLï¼ˆè¿™æ¬¡æ¯”è¾ƒçŸ­ï¼‰å’Œè¦æ±‚ï¼ˆé˜²æ­¢åç›—é“¾ã€æŽ’é™¤éƒ¨åˆ†æ ¼å¼ä¸åŒçš„é“¾æŽ¥ï¼‰ï¼Œç„¶åŽè¦æ±‚ Copilot ç”Ÿæˆè„šæœ¬ã€‚å¾ˆå¯æƒœï¼Œç»è¿‡ 17 ä¸ª Prompt çš„æ‹‰æ‰¯ï¼ŒCopilot å¹¶æœªç»™å‡ºæ»¡æ„çš„ç­”æ¡ˆï¼Œä»£ç å´æ˜¯è¶Šæ¥è¶Šé•¿ã€å¯è¯»æ€§è¶Šæ¥è¶Šä½Žã€‚

äºŽæ˜¯ï¼Œæœ¬è›¾å­åœ¨ä¸­é—´é€‰æ‹©äº†ä¸€ä¸ªè¿˜ä¸æ˜¯é‚£ä¹ˆå¤æ‚çš„ç‰ˆæœ¬ä¿®æ”¹äº†ä¸€ä¸‹ï¼Œå¤§çº¦æ”¹åŠ¨ 30 è¡Œï¼Œå¾—åˆ°äº†å¯ç”¨ä»£ç ã€‚å…·ä½“ä»£ç å…¶å®žå’Œç§€äººç½‘çš„å¾ˆåƒï¼Œä½†æ˜¯ç”±äºŽä¸æ˜¯ Copilot ç”Ÿæˆçš„ï¼Œåªèƒ½è¯´è¿™ä¸ªæŒ‘æˆ˜æ˜¯å¤±è´¥çš„ã€‚

è¯¦ç»†ä»£ç è¯·çœ‹ä»“åº“ã€‚

## ðŸ—£ æ€»ç»“

Copilot å¯¹äºŽåŽŸåˆ›è„šæœ¬çš„å¤„ç†å¾ˆå¥½ï¼Œå¯¹äºŽæ¯”è¾ƒç®€å•ã€æ¡ä»¶å……è¶³çš„é—®é¢˜ï¼Œå¾ˆå¥½çš„ç¼–ç¨‹ä¹ æƒ¯ä½¿å…¶ä»£ç å¯ç”¨æ€§å¾ˆå¼ºã€‚ä½†æ˜¯é‡åˆ°éœ€è¦ä¿®æ”¹ä»£ç é€‚åº”æ–°æƒ…å†µçš„æ—¶å€™ï¼Œå°±å‡ºçŽ°äº†ä¸€äº›é—®é¢˜ã€‚

æœ¬è›¾å­è®¤ä¸º Copilot è™½å¥½ï¼Œè¿˜æ˜¯ä¸èƒ½ä¾èµ–å®ƒï¼Œå¦åˆ™å°±é™·å…¥äº†â€œæ˜“ç”¨æ€§â€çš„å…”å­æ´žï¼Œåœ¨é‡åˆ°é—®é¢˜æ—¶æ— ä»Žä¸‹æ‰‹ï¼Œåè€Œå¢žåŠ éº»çƒ¦ã€‚
